{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam\n",
    "import skimage\n",
    "import glob\n",
    "import numpy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.measure import compare_ssim\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import mutual_info_score\n",
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('tf')\n",
    "import joblib\n",
    "#K.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = 'fer2013.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 48, 48\n",
    "\n",
    "data = pd.read_csv(filepath)\n",
    "data = data.drop(data.index[len(data)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35886, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert the data format from the original format to a 48x48 array.\n",
    "#Original format is the pixel values stored in a string, where each value is seperated by a space.\n",
    "def convert_data(data):\n",
    "    \n",
    "    X_train = data['pixels'][0].split(' ')\n",
    "    X_train = np.asarray(X_train).astype('float32')\n",
    "    X_train = X_train.reshape(1,48,48)\n",
    "    \n",
    "    Y_train = data['emotion']\n",
    "    Y_train = np.asarray(Y_train)\n",
    "    \n",
    "    for i in range(1, data.shape[0]):\n",
    "        \n",
    "        x = data['pixels'][i].split(' ')\n",
    "        x = np.asarray(x).astype('float32')\n",
    "        x = x.reshape(1,48,48)\n",
    "        X_train = np.concatenate((X_train,x), axis=0)\n",
    "\n",
    "    \n",
    "    return [X_train, Y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean(X):\n",
    "    \n",
    "    mean = np.mean(X)\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_std(X):\n",
    "    \n",
    "    std = np.std(X)\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the converted dataset\n",
    "#X, Y = convert_data(data)\n",
    "\n",
    "#joblib.dump(X, 'X.pkl')\n",
    "#joblib.dump(Y, 'Y.pkl')\n",
    "\n",
    "#Load the saved dataset\n",
    "X = joblib.load('X.pkl')\n",
    "Y = joblib.load('Y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35886, 48, 48)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_img(img):\n",
    "    img = imgToarr(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function converts the image to a numpy array\n",
    "def imgToarr(img):\n",
    "    \n",
    "    return numpy.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Resizes the image to the specified dimensions\n",
    "def resize(img,x,y):\n",
    "    \n",
    "    return img.resize((x,y),Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting a N-Dimensional array to 1-D array\n",
    "def reshape_1D(arr):\n",
    "    \n",
    "    return arr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_to_numpyarray(convert_list):\n",
    "    \n",
    "    return np.asarray(convert_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X[0:28709]\n",
    "Y_train = Y[0:28709]\n",
    "X_test = X[28709:]\n",
    "Y_test = Y[28709:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = Y_train.reshape(Y_train.shape[0],1)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train -= np.mean(X_train)\n",
    "X_train /= np.std(X_train)\n",
    "X_test -= np.mean(X_test)\n",
    "X_test /= np.std(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 7\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initializing the values for the convolution neural network\n",
    "nb_epoch = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(64, (3, 3), padding='same',\n",
    "                        input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 7177 samples\n",
      "Epoch 1/100\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.8124 - acc: 0.2493Epoch 00001: val_acc improved from -inf to 0.25596, saving model to emotion1.h5\n",
      "28709/28709 [==============================] - 782s 27ms/step - loss: 1.8123 - acc: 0.2492 - val_loss: 1.7793 - val_acc: 0.2560\n",
      "Epoch 2/100\n",
      "28672/28709 [============================>.] - ETA: 1s - loss: 1.7720 - acc: 0.2626Epoch 00002: val_acc improved from 0.25596 to 0.27602, saving model to emotion1.h5\n",
      "28709/28709 [==============================] - 1018s 35ms/step - loss: 1.7721 - acc: 0.2626 - val_loss: 1.7527 - val_acc: 0.2760\n",
      "Epoch 3/100\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.7220 - acc: 0.3060Epoch 00003: val_acc improved from 0.27602 to 0.34513, saving model to emotion1.h5\n",
      "28709/28709 [==============================] - 824s 29ms/step - loss: 1.7219 - acc: 0.3059 - val_loss: 1.6654 - val_acc: 0.3451\n",
      "Epoch 4/100\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.6262 - acc: 0.3614Epoch 00004: val_acc improved from 0.34513 to 0.39111, saving model to emotion1.h5\n",
      "28709/28709 [==============================] - 790s 28ms/step - loss: 1.6257 - acc: 0.3617 - val_loss: 1.5753 - val_acc: 0.3911\n",
      "Epoch 5/100\n",
      "28672/28709 [============================>.] - ETA: 0s - loss: 1.5536 - acc: 0.3976Epoch 00005: val_acc improved from 0.39111 to 0.42427, saving model to emotion1.h5\n",
      "28709/28709 [==============================] - 818s 28ms/step - loss: 1.5535 - acc: 0.3976 - val_loss: 1.5217 - val_acc: 0.4243\n",
      "Epoch 6/100\n",
      "28672/28709 [============================>.] - ETA: 1s - loss: 1.5139 - acc: 0.4193Epoch 00006: val_acc did not improve\n",
      "28709/28709 [==============================] - 892s 31ms/step - loss: 1.5139 - acc: 0.4194 - val_loss: 1.4975 - val_acc: 0.4240\n",
      "Epoch 7/100\n",
      "25920/28709 [==========================>...] - ETA: 1:27 - loss: 1.4854 - acc: 0.4321"
     ]
    }
   ],
   "source": [
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "filepath=\"emotion1.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, callbacks=callbacks_list, \\\n",
    "          validation_data=(X_test, Y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
